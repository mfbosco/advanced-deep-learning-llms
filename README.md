# Aprendizado Profundo Avan√ßado: LLMs e Agentes Inteligentes na Pr√°tica

Este reposit√≥rio cont√©m materiais, exerc√≠cios e projetos desenvolvidos durante o curso de Aprendizado Profundo Avan√ßado: LLMs e Agentes Inteligentes na Pr√°tica (IA368HH) da FEEC Unicamp durante o segundo semestre de 2025.

## üìö Sobre o Curso

Curso focado no estudo te√≥rico e pr√°tico de modelos de linguagem de grande escala (LLMs), abordando desde os fundamentos at√© t√©cnicas avan√ßadas de fine-tuning e aplica√ß√µes pr√°ticas.

## üóÇÔ∏è Estrutura do Reposit√≥rio

### [01. An√°lise de Sentimentos](01-sentimental-analisys/)
Trabalho de processo seletivo focado em an√°lise de sentimentos no dataset IMDB utilizando:
- Bag of Words (BoW)
- Redes Neurais com PyTorch
- An√°lise explorat√≥ria de dados
- Modelo MLP para classifica√ß√£o de sentimentos

### [02. Modelagem da Linguagem](02-language-model/)
Implementa√ß√£o do modelo de linguagem neural proposto por Bengio (2003):
- Redes Neurais MLP
- Word Embeddings
- Prepara√ß√£o de dados para modelos de linguagem

### [03. Attention](03-attention/)
Estudo e implementa√ß√£o do mecanismo de aten√ß√£o:
- Self-Attention
- Multi-Head Attention
- Fundamentos para Transformers

### [04. BERT](04-BERT/)
Explora√ß√£o do modelo BERT (Bidirectional Encoder Representations from Transformers):
- Arquitetura BERT
- Fine-tuning para tarefas espec√≠ficas
- Modelos BERT-Tiny e adapta√ß√µes
- Treinamento em portugu√™s

### [05. GPT-2](05-GPT-2/)
Estudo de modelos autoregressivos:
- M√°scaras causais
- Arquitetura GPT
- Implementa√ß√£o de micro-transformer
- Gera√ß√£o de texto

### [06. LoRA](06-LoRA/)
T√©cnicas de fine-tuning eficiente:
- Low-Rank Adaptation (LoRA)
- Parameter-Efficient Fine-Tuning (PEFT)
- Otimiza√ß√£o de modelos grandes

### [07. CLIP](07-CLIP/)
Modelos multimodais:
- Contrastive Language-Image Pre-training (CLIP)
- Embeddings multimodais
- Alinhamento texto-imagem

### [08. RAG](08-RAG/)
Retrieval-Augmented Generation:
- Sistemas de recupera√ß√£o de informa√ß√£o
- Integra√ß√£o de recupera√ß√£o com gera√ß√£o
- Aplica√ß√µes pr√°ticas de RAG

### [09. GPT-3](09-GPT-3/)
Prompting e t√©cnicas avan√ßadas:
- Chain-of-Thought (CoT)
- Few-shot learning
- Zero-shot learning
- Compara√ß√£o de estrat√©gias de prompting

### [10. ReACT](10-ReACT/)
Reasoning and Acting:
- Integra√ß√£o de racioc√≠nio e a√ß√£o
- Agentes baseados em LLMs
- Implementa√ß√µes pr√°ticas

### [11. Multi Agentes](11-multi-agentes/)
Sistemas multi-agentes:
- Coordena√ß√£o entre agentes
- Comunica√ß√£o e colabora√ß√£o
- Arquiteturas distribu√≠das

### [12. Projeto Final](https://github.com/GabrielCFreitas/multimodal-rag-med)
Projeto de conclus√£o do curso aplicando os conhecimentos adquiridos com a contribui√ß√£o de [@GabrielCFreitas](https://github.com/GabrielCFreitas).  
O projeto escolhido foi o desenvolvimento de um sistema RAG Multimodal para imagens e textos m√©dicos. O desenvolimento e resultados podem ser consultados no reposit√≥rio [multimodal-rag-med](https://github.com/GabrielCFreitas/multimodal-rag-med).

## üõ†Ô∏è Tecnologias Utilizadas

- **Python**: Linguagem principal
- **PyTorch**: Framework de deep learning
- **Transformers (Hugging Face)**: Biblioteca de modelos pr√©-treinados
- **Jupyter Notebooks**: Ambiente de desenvolvimento interativo
- **NumPy & Pandas**: Manipula√ß√£o de dados

---

**√öltima atualiza√ß√£o**: Janeiro de 2026
