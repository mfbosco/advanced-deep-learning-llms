# LoRA (Low-Rank Adaptation)

## Objetivo

Implementar e comparar **LoRA** (Low-Rank Adaptation) como t√©cnica eficiente de fine-tuning de modelos de linguagem, reduzindo drasticamente o n√∫mero de par√¢metros trein√°veis.

## Estrutura

```
git/06-LoRA/
‚îú‚îÄ‚îÄ exercicio_LoRA.ipynb      # Implementa√ß√£o LoRA
‚îî‚îÄ‚îÄ comentario_LoRA.pdf       # Material complementar
```

## Conceitos Principais

### LoRA (Low-Rank Adaptation)
- **Decomposi√ß√£o de baixo rank**: Em vez de ajustar todos os pesos `W`, adiciona adapta√ß√£o via matrizes menores `A` e `B`
- **F√≥rmula**: `W' = W + BA`, onde `A ‚àà ‚Ñù^(d√ór)` e `B ‚àà ‚Ñù^(r√ód)` com `r << d`
- **Vantagem**: Reduz par√¢metros trein√°veis mantendo o modelo base congelado
- **Scaling factor**: `Œ±/r` para controlar magnitude da adapta√ß√£o

### Compara√ß√£o com Fine-Tuning Total
- **Modelo base**: ~8.2M par√¢metros trein√°veis (fine-tuning completo)
- **Modelo LoRA**: Apenas matrizes `A` e `B` s√£o trein√°veis (rank `r=4`)
- **Efici√™ncia**: Menos mem√≥ria, treinamento mais r√°pido, mesma performance

## Implementa√ß√£o

### 1. Camada LoRA
```python
class LoRALayer(nn.Module):
    def __init__(self, in_features, out_features, rank=4, alpha=1.0):
        super().__init__()
        # Matrizes de baixo rank
        self.lora_A = nn.Parameter(torch.randn(in_features, rank) * 0.01)
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))
        self.scaling = alpha / rank
    
    def forward(self, x):
        # LoRA: h = x @ (B @ A^T) * scaling
        delta_W = self.lora_B @ self.lora_A.T
        h = x @ delta_W.T
        return h * self.scaling
```

### 2. Linear com LoRA
```python
class LoRALinear(nn.Module):
    """
    Transforma uma camada linear com LoRA.
    """
    def __init__(self, original_layer, rank=4, alpha=1.0):
        super().__init__()
        self.original_layer = original_layer
        self.lora = LoRALayer(original_layer.in_features, original_layer.out_features, rank, alpha)

        for param in self.original_layer.parameters():
            param.requires_grad = False

    def forward(self, x):
        return self.original_layer(x) + self.lora(x) # y = Wx + h
```

### 3. Aplicar LoRA ao Modelo
```python
def apply_lora_to_model(model, rank=4, alpha=1.0):
    """
    Retorna uma c√≥pia do modelo com todas as camadas nn.Linear substitu√≠das por LoRALinear.
    O modelo original N√ÉO √© modificado.
    """
    model = copy.deepcopy(model)  # Faz uma c√≥pia profunda do modelo original
    for name, child in model.named_children():
        if isinstance(child, nn.Linear):
            setattr(model, name, LoRALinear(child, rank=rank, alpha=alpha))
        else:
            setattr(model, name, apply_lora_to_model(child, rank=rank, alpha=alpha))

    return model
```

## Pipeline de Treinamento

### Etapas
1. **Pr√©-treino do modelo base**: Treinar modelo completo com m√°scara causal (80% dos dados)
2. **Aplicar LoRA**: Converter camadas lineares para LoRALinear com `rank=4`
3. **Fine-tuning LoRA**: Treinar apenas matrizes `A` e `B` (20% dos dados)
4. **Compara√ß√£o**: Avaliar perplexidade e qualidade de gera√ß√£o

### Hiperpar√¢metros
```python
# Modelo base (pr√©-treino)
epochs = 10
lr = 0.01
optimizer = AdamW(model.parameters(), lr=lr)

# LoRA (fine-tuning)
epochs_lora = 5
lr_lora = 0.001
rank = 4
alpha = 1.0
optimizer_lora = AdamW(
    filter(lambda p: p.requires_grad, lora_model.parameters()), 
    lr=lr_lora
)
```

## Resultados Esperados

- **Efici√™ncia**: Redu√ß√£o dr√°stica de par√¢metros trein√°veis mantendo performance
- **Perplexidade**: Similar ao fine-tuning completo
- **Gera√ß√£o**: Qualidade compar√°vel com custos computacionais menores
- **Aplica√ß√µes**: Fine-tuning eficiente para tarefas espec√≠ficas

## üìñ Refer√™ncia

**Hu, Edward J., et al. (2021)**  
[*"LoRA: Low-Rank Adaptation of Large Language Models"*](https://arxiv.org/pdf/2106.09685)  
